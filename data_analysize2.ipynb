{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e610a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集总数: 7682\n",
      "测试数据集总数: 1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaofengwo/runtime/spark-3.2.0-bin-hadoop3.2/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression classifier Accuracy:0.7738\n",
      "LogisticRegression classifier Auc:0.8524\n",
      "DecisionTree classifier Accuracy:0.7864\n",
      "DecisionTree classifier Auc:0.7922\n",
      "Random Forest classifier Accuracy:0.7864\n",
      "Random Forest classifier Auc:0.8593\n",
      "GBT classifier Accuracy:0.7911\n",
      "GBT classifier Auc:0.8636\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier,DecisionTreeClassifier,LogisticRegression,GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator,BinaryClassificationEvaluator\n",
    "from pyspark.sql.types import StringType, IntegerType, StructField, StructType\n",
    "from pyspark.ml.stat import Correlation\n",
    "import pandas as pd\n",
    "\n",
    "def initialize(txt_file):\n",
    "#     sc = SparkContext('local', 'spark_project')\n",
    "#     sc.setLogLevel('WARN')\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    fields = [StructField(\"up\", StringType(), False), StructField(\"time\", StringType(), False),\n",
    "              StructField(\"title\", StringType(), False),StructField(\"desc\", StringType(), False),\n",
    "              StructField(\"view\", IntegerType(), False), StructField(\"danmaku\", IntegerType(), False),\n",
    "              StructField(\"reply\", IntegerType(), False), StructField(\"favorite\", IntegerType(), False),\n",
    "              StructField(\"coin\", IntegerType(), False), StructField(\"share\", IntegerType(), False),\n",
    "              StructField(\"like\", IntegerType(), False), StructField(\"rcmd_reason\", StringType(), False),\n",
    "              StructField(\"tname\", StringType(), False), StructField(\"his_rank\", IntegerType(), False), ]\n",
    "    schema = StructType(fields)\n",
    "    rdd = spark.sparkContext.textFile(txt_file)\\\n",
    "        .map(lambda x: x.split(\"\\t\")).map(lambda x:Row(x[0],x[1],x[2],x[3],int(x[4]),int(x[5]),int(x[6]),\\\n",
    "                                                        int(x[7]),int(x[8]),int(x[9]),int(x[10]),x[11],x[12],int(x[13])))\n",
    "    data = spark.createDataFrame(rdd, schema)\n",
    "    return data\n",
    "\n",
    "def transform_data(df):\n",
    "    # 删除掉无用的数据\n",
    "    df = df.drop('up')\n",
    "    df = df.drop('time')\n",
    "    df = df.drop('title')\n",
    "    df = df.drop('desc')\n",
    "    df = df.drop('rcmd_reason')\n",
    "    df = df.drop('tname')\n",
    "    # 根据历史排名his_rank，新增类别标签label\n",
    "    df = df.withColumn('label', when(df.his_rank <= 10, 1).otherwise(0))\n",
    "\n",
    "    # 将数据转为特征向量\n",
    "    required_features = ['view','danmaku','reply','favorite','coin','share','like']\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=required_features,\n",
    "        outputCol='features')\n",
    "    transformed_data = assembler.transform(df)\n",
    "\n",
    "    #对数据进行划分\n",
    "    (training_data, test_data) = transformed_data.randomSplit([0.8, 0.2], seed=2023)\n",
    "    print(\"训练数据集总数: \" + str(training_data.count()))\n",
    "    print(\"测试数据集总数: \" + str(test_data.count()))\n",
    "    return transformed_data,training_data,test_data\n",
    "\n",
    "def corr_matrix(df,cor_save_dir):\n",
    "    cor_mat = Correlation.corr(df, \"features\", \"spearman\").head()[0]\n",
    "    cor_df = pd.DataFrame(cor_mat.toArray())\n",
    "    cor_df.columns = ['view','danmaku','reply','favorite','coin','share','like']\n",
    "    cor_df.to_csv(cor_save_dir, index=False)\n",
    "\n",
    "\n",
    "def LogisticReg(training_data,test_data):\n",
    "    # 实例化逻辑回归算法\n",
    "    lr = LogisticRegression(labelCol='label',featuresCol='features',maxIter=15)\n",
    "    # 进行模型训练\n",
    "    model = lr.fit(training_data)\n",
    "    # 进行模型验证\n",
    "    lr_predictions = model.transform(test_data)\n",
    "    # 计算分类acc\n",
    "    multi_evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol='label', metricName='accuracy')\n",
    "    acc = multi_evaluator.evaluate(lr_predictions)\n",
    "    print('LogisticRegression classifier Accuracy:{:.4f}'.format(acc))\n",
    "    # 计算模型auc\n",
    "    binary_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\",\n",
    "        metricName=\"areaUnderROC\")\n",
    "    auc = binary_evaluator.evaluate(lr_predictions)\n",
    "    print('LogisticRegression classifier Auc:{:.4f}'.format(auc))\n",
    "    return ['LogisticRegression',acc,auc]\n",
    "\n",
    "def DecisionTree(training_data,test_data):\n",
    "    # 实例化决策树算法\n",
    "    dt = DecisionTreeClassifier(labelCol='label',\n",
    "                                featuresCol='features',\n",
    "                                maxDepth =5)\n",
    "    # 进行模型训练\n",
    "    model = dt.fit(training_data)\n",
    "    # 进行模型验证\n",
    "    dt_predictions = model.transform(test_data)\n",
    "    # 计算分类acc\n",
    "    multi_evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol='label', metricName='accuracy')\n",
    "    acc = multi_evaluator.evaluate(dt_predictions)\n",
    "    print('DecisionTree classifier Accuracy:{:.4f}'.format(acc))\n",
    "    # 计算模型auc\n",
    "    binary_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\",\n",
    "        metricName=\"areaUnderROC\")\n",
    "    auc = binary_evaluator.evaluate(dt_predictions)\n",
    "    print('DecisionTree classifier Auc:{:.4f}'.format(auc))\n",
    "    return ['DecisionTree',acc,auc]\n",
    "\n",
    "def Randomforest(training_data,test_data):\n",
    "    # 实例化随机森林算法\n",
    "    rf = RandomForestClassifier(labelCol='label',\n",
    "                                featuresCol='features',\n",
    "                                maxDepth=5)\n",
    "    # 进行模型训练\n",
    "    model = rf.fit(training_data)\n",
    "    # 进行模型验证\n",
    "    rf_predictions = model.transform(test_data)\n",
    "    # 计算分类acc\n",
    "    multi_evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol='label', metricName='accuracy')\n",
    "    acc = multi_evaluator.evaluate(rf_predictions)\n",
    "    print('Random Forest classifier Accuracy:{:.4f}'.format(acc))\n",
    "    # 计算模型auc\n",
    "    binary_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\",\n",
    "        metricName=\"areaUnderROC\")\n",
    "    auc = binary_evaluator.evaluate(rf_predictions)\n",
    "    print('Random Forest classifier Auc:{:.4f}'.format(auc))\n",
    "    return ['Random Forest',acc,auc]\n",
    "\n",
    "\n",
    "def GBT(training_data,test_data):\n",
    "    # 实例化GBT算法\n",
    "    gb = GBTClassifier(labelCol='label',featuresCol='features',maxDepth=5)\n",
    "    # 进行模型训练\n",
    "    model = gb.fit(training_data)\n",
    "    # 进行模型预测\n",
    "    gb_predictions = model.transform(test_data)\n",
    "    # 计算分类acc\n",
    "    multi_evaluator = MulticlassClassificationEvaluator(labelCol='label', metricName='accuracy')\n",
    "    acc = multi_evaluator.evaluate(gb_predictions)\n",
    "    print('GBT classifier Accuracy:{:.4f}'.format(acc))\n",
    "    # 计算模型auc\n",
    "    binary_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\",\n",
    "        metricName=\"areaUnderROC\")\n",
    "    auc = binary_evaluator.evaluate(gb_predictions)\n",
    "    print('GBT classifier Auc:{:.4f}'.format(auc))\n",
    "    return ['GBT',acc,auc]\n",
    "\n",
    "\n",
    "\n",
    "def train(df,cor_dir,classifier_comparison_dir):\n",
    "    transformed_data,training_data, test_data = transform_data(df)\n",
    "    # 计算变量之间的相关性\n",
    "    corr_matrix(transformed_data,cor_dir)\n",
    "    # 使用四种分类器进行分类\n",
    "    log_res = LogisticReg(training_data, test_data)\n",
    "    dt_res = DecisionTree(training_data, test_data)\n",
    "    rf_res = Randomforest(training_data, test_data)\n",
    "    gbt_res = GBT(training_data, test_data)\n",
    "    # 将分类器的性能结果保存在csv文件中\n",
    "    classifier_comparison = [log_res,dt_res,rf_res,gbt_res]\n",
    "    comparison_df = pd.DataFrame(classifier_comparison)\n",
    "    comparison_df.columns = ['classifier','Acc','Auc']\n",
    "    comparison_df.to_csv(classifier_comparison_dir,index = False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    csv_file = 'hdfs://master:8020/data/bilibili_week.txt'\n",
    "    static_dir = './static'\n",
    "    cor_save = os.path.join(static_dir,'cor_matrix.csv')\n",
    "    classifier_comparison_dir = os.path.join(static_dir,'comparison.csv')\n",
    "    df = initialize(csv_file)\n",
    "    train(df,cor_save,classifier_comparison_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8158ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
